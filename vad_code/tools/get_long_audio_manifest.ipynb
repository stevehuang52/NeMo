{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-02-21 16:41:58 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-02-21 16:41:58 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:04 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:05 nemo_logging:349] /home/heh/anaconda3/envs/develop/lib/python3.8/site-packages/torch/jit/annotations.py:296: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2023-02-21 16:42:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-02-21 16:42:05 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.parts.utils import vad_utils\n",
    "\n",
    "from math import ceil\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Global constants\n",
    "window_length_in_sec = 0.01\n",
    "split_duration = 20.0\n",
    "num_workers = 12\n",
    "prepared_manifest_vad_input = \"temp_manifest.json\"\n",
    "\n",
    "\n",
    "def load_file(filepath):\n",
    "    results = []\n",
    "    with Path(filepath).open(\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            results.append(line.strip())\n",
    "    return results\n",
    "\n",
    "def change_prefix_dir(data: list, prefix: Path, key: str = \"vad_sd\"):\n",
    "    results = []\n",
    "    for item in data:\n",
    "        idx = item.index(key)\n",
    "        filename = Path(item[idx+len(key)+1:])\n",
    "        res = prefix / filename\n",
    "        results.append(str(res))\n",
    "    return results\n",
    "\n",
    "def load_manifest(filepath):\n",
    "    results = []\n",
    "    with Path(filepath).open(\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            results.append(json.loads(line.strip()))\n",
    "    return results\n",
    "\n",
    "def save_manifest(filepath, manifest):\n",
    "    with Path(filepath).open('w') as fout:\n",
    "        for item in manifest:\n",
    "            fout.write(f\"{json.dumps(item)}\\n\")\n",
    "\n",
    "def load_rttm_file(filepath):\n",
    "    data = pd.read_csv(filepath, sep=\"\\s+\", delimiter=None, header=None)\n",
    "    data = data.rename(columns={3: \"start\", 4: \"dur\", 7: \"speaker\"})\n",
    "\n",
    "    data['start'] = data['start'].astype(float)\n",
    "    data['dur'] = data['dur'].astype(float)\n",
    "    data['end']= data['start'] + data['dur']\n",
    "\n",
    "    data = data.sort_values(by=['start'])\n",
    "    data['segment'] = list(zip(data['start'], data['end']))\n",
    "\n",
    "    return data\n",
    "\n",
    "def build_map(file_list):\n",
    "    results = {}\n",
    "    for item in file_list:\n",
    "        key = Path(item).stem\n",
    "        if key in results:\n",
    "            raise ValueError(f\"filenames must be unique, but got {item} as duplicate.\")\n",
    "        results[key] = item\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_temp_manifest(audio_list, rttm_list):\n",
    "    temp_manifest = []\n",
    "    audio_file_map = build_map(audio_list)\n",
    "    rttm_file_map = build_map(rttm_list)\n",
    "    for key, val in audio_file_map.items():\n",
    "        if key not in rttm_file_map:\n",
    "            print(f\"Key {key} not in rttm list, skipping...\")\n",
    "            continue\n",
    "\n",
    "        item = {\n",
    "            \"audio_filepath\": str(val),\n",
    "        }\n",
    "        temp_manifest.append(item)\n",
    "    \n",
    "    config = {\n",
    "            'input': temp_manifest,\n",
    "            'window_length_in_sec': window_length_in_sec,\n",
    "            'split_duration': split_duration,\n",
    "            'num_workers': num_workers,\n",
    "            \"prepared_manifest_vad_input\": prepared_manifest_vad_input\n",
    "        }\n",
    "    \n",
    "    manifest_vad_input = vad_utils.prepare_manifest(config)\n",
    "    data = load_manifest(manifest_vad_input)\n",
    "\n",
    "    results = []\n",
    "    for item in data:\n",
    "        key = Path(item[\"audio_filepath\"]).stem\n",
    "        item[\"rttm_file\"] = rttm_file_map[key]\n",
    "        results.append(item)\n",
    "    return results\n",
    "\n",
    "\n",
    "def merge_intervals(intervals: List[List[float]]) -> List[List[float]]:\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for interval in intervals:\n",
    "        # if the list of merged intervals is empty or if the current\n",
    "        # interval does not overlap with the previous, simply append it.\n",
    "        if not merged or merged[-1][1] < interval[0]:\n",
    "            merged.append(interval)\n",
    "        else:\n",
    "        # otherwise, there is overlap, so we merge the current and previous\n",
    "        # intervals.\n",
    "            merged[-1][1] = max(merged[-1][1], interval[1])\n",
    "    return merged\n",
    "\n",
    "def get_speech_segments(rttm_file):\n",
    "    speech_segments = list(load_rttm_file(rttm_file)['segment'])\n",
    "    speech_segments = [list(x) for x in speech_segments]\n",
    "    speech_segments = merge_intervals(speech_segments)\n",
    "    return speech_segments\n",
    "\n",
    "\n",
    "def get_speech_segments_map(rttm_list):\n",
    "    results = dict()\n",
    "    for rttm_file in rttm_list:\n",
    "        key = Path(rttm_file).stem\n",
    "        results[key] = get_speech_segments(rttm_file)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_frame_labels(segments: List[List[float]], frame_length: float, offset: float, duration: float, sid: int = 0):\n",
    "    labels = []\n",
    "    n_frames = ceil(duration / frame_length)\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        t = offset + i * frame_length\n",
    "        while sid < len(segments) - 1 and segments[sid][1] < t:\n",
    "            sid += 1\n",
    "        if segments[sid][0] <= t <= segments[sid][1]:\n",
    "            labels.append('1')\n",
    "        else:\n",
    "            labels.append('0')\n",
    "    return ' '.join(labels), sid\n",
    "\n",
    "def get_frame_manifest(manifest: List[Dict], segments_map: Dict, frame_length: float):\n",
    "    results = []\n",
    "    for item in tqdm(manifest):\n",
    "        rttm_key = Path(item['rttm_file']).stem\n",
    "        item['label'], _ = get_frame_labels(segments_map[rttm_key], frame_length, item['offset'], item['duration'])\n",
    "        results.append(item)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "['/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_0.wav', '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_1.wav', '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_10.wav'] ['/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_0.rttm', '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_1.rttm', '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_10.rttm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting manifest: 100%|██████████| 10000/10000 [02:05<00:00, 79.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_filepath': '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_0.wav', 'duration': 20.0, 'label': 'infer', 'text': '_', 'offset': 0, 'rttm_file': '/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h/fisher_spks5_360s_0.rttm'}\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183088/183088 [00:22<00:00, 8244.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "frame_length = 0.04\n",
    "data_dir = Path(\"/media/data2/simulated_data/fisher-clean/dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h\")\n",
    "audio_list = sorted([str(x) for x in data_dir.glob(\"*.wav\")])\n",
    "rttm_list = sorted([str(x) for x in data_dir.glob(\"*.rttm\")])\n",
    "print(len(audio_list))\n",
    "print(len(rttm_list))\n",
    "print(audio_list[:3], rttm_list[:3])\n",
    "temp_manifest = get_temp_manifest(audio_list, rttm_list)\n",
    "print(temp_manifest[0])\n",
    "all_segments_map = get_speech_segments_map(rttm_list)\n",
    "print(len(all_segments_map))\n",
    "new_manifest = get_frame_manifest(temp_manifest, all_segments_map, frame_length)\n",
    "save_manifest(f\"fisher_dur360_spks5_turnP0.85_ovl0.1x0.005_sln0.3x0.005_seed5_1000h_20s.json\", new_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/data/vad_sd/ch120/audio/en_4629.wav']\n",
      "['/mnt/data/vad_sd/ch120/rttm/en_4629.rttm']\n",
      "['/media/data/datasets/vad_sd/ch120/audio/en_4629.wav']\n",
      "['/media/data/datasets/vad_sd/ch120/rttm/en_4629.rttm']\n"
     ]
    }
   ],
   "source": [
    "data_root = Path(\"/media/data/datasets/vad_sd/\")\n",
    "\n",
    "data_name = \"ch120\"\n",
    "data_dir = data_root / Path(data_name)\n",
    "annotation_files_dir = data_dir / Path(\"list\")\n",
    "\n",
    "split = \"CH109\"\n",
    "audio_list_file = annotation_files_dir / Path(f\"audio_{split}list.txt\")\n",
    "rttm_list_file = annotation_files_dir / Path(f\"rttm_{split}list.txt\")\n",
    "\n",
    "audio_list = load_file(audio_list_file)\n",
    "rttm_list = load_file(rttm_list_file)\n",
    "print(audio_list[:1])\n",
    "print(rttm_list[:1])\n",
    "audio_list = change_prefix_dir(audio_list, data_root)\n",
    "rttm_list = change_prefix_dir(rttm_list, data_root)\n",
    "print(audio_list[:1])\n",
    "print(rttm_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:02<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-10-04 14:12:59 vad_utils:89] The prepared manifest file exists. Overwriting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_filepath': '/media/data/datasets/vad_sd/ch120/audio/en_4629.wav', 'duration': 20.0, 'label': 'infer', 'text': '_', 'offset': 0, 'rttm_file': '/media/data/datasets/vad_sd/ch120/rttm/en_4629.rttm'}\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 329/329 [00:00<00:00, 7328.14it/s]\n"
     ]
    }
   ],
   "source": [
    "frame_length = 0.04\n",
    "temp_manifest = get_temp_manifest(audio_list, rttm_list)\n",
    "print(temp_manifest[0])\n",
    "all_segments_map = get_speech_segments_map(rttm_list)\n",
    "print(len(all_segments_map))\n",
    "new_manifest = get_frame_manifest(temp_manifest, all_segments_map, frame_length)\n",
    "save_manifest(f\"{data_name}_{split}_40ms.json\", new_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_data_prefix(filepath, src, dst):\n",
    "    data = load_manifest(filepath)\n",
    "    results = []\n",
    "    for item in data:\n",
    "        for key in [\"audio_filepath\", \"rttm_file\"]:\n",
    "            if key in item and item[key].startswith(src):\n",
    "                idx = item[key].index(src)\n",
    "                new_path = Path(dst) / Path(item[key][idx + len(src) + 1:])\n",
    "                item[key] = str(new_path)\n",
    "        results.append(item)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved manifests_long/ami_eval_20ms_drc.json\n",
      "saved manifests_long/ami_train_40ms_drc.json\n",
      "saved manifests_long/ch120_CH109_40ms_drc.json\n",
      "saved manifests_long/ami_dev_40ms_drc.json\n",
      "saved manifests_long/icsi_all_40ms_drc.json\n",
      "saved manifests_long/ch120_moved_40ms_drc.json\n",
      "saved manifests_long/fisher_2005_40ms_drc.json\n",
      "saved manifests_long/ami_eval_40ms_drc.json\n",
      "saved manifests_long/fisher_2004_40ms_drc.json\n"
     ]
    }
   ],
   "source": [
    "for manifest in Path('./manifests_long/').glob('*.json'):\n",
    "    if 'drc' in str(manifest):\n",
    "        continue\n",
    "    parent = manifest.parent\n",
    "    output = Path(parent) / Path(f\"{manifest.stem}_drc.json\")\n",
    "    data = change_data_prefix(manifest, '/media/data/datasets/vad_sd', '/data')\n",
    "    save_manifest(output, data)\n",
    "    print(f\"saved {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process AVA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/media/data/datasets/ava/nnlabel/2PpxiG0WU18.label'), PosixPath('/media/data/datasets/ava/nnlabel/J4bt4y9ShTA.label'), PosixPath('/media/data/datasets/ava/nnlabel/AN07xQokfiE.label'), PosixPath('/media/data/datasets/ava/nnlabel/Ov0za6Xb1LM.label'), PosixPath('/media/data/datasets/ava/nnlabel/K_SpqDJnlps.label')]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "label_dir = Path(\"/media/data/datasets/ava/nnlabel\")\n",
    "label_files = list(label_dir.glob(\"*.label\"))\n",
    "\n",
    "all_labels_map = defaultdict(list)\n",
    "for filepath in label_files:\n",
    "    key = filepath.stem\n",
    "    labels = []\n",
    "    with Path(filepath).open(\"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            label = line.strip()\n",
    "            if not label:\n",
    "                continue\n",
    "            if label == \"NO_SPEECH\":\n",
    "                labels.append('0')\n",
    "            else:\n",
    "                labels.append('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bf5878059d4e9c1f9c41bd997ee15b5cf7f5fa7f22eb5fb573f4f61b5eb976a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
